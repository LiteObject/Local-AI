# What I'm Actually Using Right Now (August 2025)

*Last updated after checking the latest Ollama library offerings*

## ðŸš€ My current go-to models

### If you're just getting started
- **llama3.2:3b** - Still my #1 recommendation for beginners
- **phi3.5:3.8b** - Microsoft's solid alternative  
- **qwen2.5:7b** - Best choice if you need multiple languages
- **smollm2:1.7b** - New lightweight option that's surprisingly capable

### For coding stuff
- **qwen2.5-coder:7b** - This has become my daily driver for coding help
- **deepseek-coder-v2:16b** - Amazing if you've got the hardware to run it
- **granite3-dense:8b** - IBM's latest, really improved from granite-code
- **starcoder2:7b** - Strong alternative for code generation

### If you've got a powerful machine
- **qwen2.5:32b** - Really impressive performance
- **llama3.3:70b** - Meta's latest large model
- **deepseek-r1:7b** - New reasoning-focused model that's impressive
- **mistral-nemo:12b** - Great balance of capability and efficiency

## ðŸ“Š What's still worth using vs what's getting old

### âœ… Models that are still current and good
- llama3.2:3b (my daily driver)
- llama3.3:70b (Meta's newest, if you can run it)
- phi3.5:3.8b (reliable and efficient)
- qwen2.5 series (7b, 14b, 32b - all solid)
- gemma2:9b, gemma2:27b (Google's offerings, very capable)
- qwen2.5-coder:7b (still the best general coding model)
- deepseek-coder-v2:16b (if you can run it)
- deepseek-r1:7b (new reasoning model, really impressive)
- mistral-nemo:12b (excellent quality)
- granite3-dense:8b (IBM's improved version)
- smollm2:1.7b (surprisingly good for its size)

### ðŸ”„ Models you should probably replace
- **granite-code:8b** â†’ Switch to **granite3-dense:8b** (newer version)
- **codellama:7b** â†’ Switch to **qwen2.5-coder:7b** or **starcoder2:7b**
- **llama3.1:8b** â†’ Consider **llama3.2:8b** or **llama3.3:70b** for improvements

### ðŸ†• New stuff worth checking out (August 2025)
- **deepseek-r1** series - New reasoning-focused models that are really good at complex problems
- **granite3-dense** series - IBM's latest, much improved from the original granite models
- **smollm2** series - Microsoft's new small models that punch above their weight
- **starcoder2** series - Updated coding models with better performance
- **gemma2:27b** - Google's larger Gemma model for better performance

## ðŸŽ¯ Just tell me what to download

**Want to try AI for the first time?**
â†’ `ollama run llama3.2:3b`

**Need help with programming?**
â†’ `ollama run qwen2.5-coder:7b`

**Work in multiple languages?**
â†’ `ollama run qwen2.5:7b`

**Got a beast machine and want the best?**
â†’ `ollama run llama3.3:70b` or `ollama run deepseek-r1:32b`

**Want something balanced and reliable?**
â†’ `ollama run mistral-nemo:12b`

**Need lightweight but capable?**
â†’ `ollama run smollm2:1.7b`

**Want the latest reasoning capabilities?**
â†’ `ollama run deepseek-r1:7b`

## ðŸ’¡ Some practical advice

1. **Don't start with the biggest model** - Begin with 3B-7B, upgrade later if needed
2. **Try the new reasoning models** - deepseek-r1 series is genuinely impressive for complex problems
3. **Watch your resources** - Keep an eye on RAM/VRAM usage, especially at first
4. **Use specialized models** - Coding models really are better at coding, reasoning models excel at complex problems
5. **Check back regularly** - New models drop frequently, and some are genuinely better

---
*I try to keep this updated as I test new models and see what's actually working well in practice. Last checked: August 2025*
